# Решающие деревья

Решающие деревья относятся к классу логических методов. Их основная идея состоит в объединении определенного количества простых решающих правил, благодаря чему итоговый алгоритм является интерпретируемым. Как следует из названия, решающее дерево представляет собой бинарное дерево, в котором каждой вершине сопоставлено некоторое правило вида "j-й признак имеет значение меньше b". В листьях этого дерева записаны числа-предсказания. Чтобы получить ответ, нужно стартовать из корня и делать переходы либо в левое, либо в правое поддерево в зависимости от того, выполняется правило из текущей вершины или нет.

Одна из особенностей решающих деревьев заключается в том, что они позволяют получать важности всех используемых признаков. Важность признака можно оценить на основе того, как сильно улучшился критерий качества благодаря использованию этого признака в вершинах дерева.

#### Материалы

- [Подробнее про решающие деревья в sklearn](http://scikit-learn.org/stable/modules/tree.html)
- [Работа с пропущенными значениями в pandas](http://pandas.pydata.org/pandas-docs/stable/missing_data.html)
- [Подробнее о деревьях и их построении](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/lecture-notes/lecture07-trees.pdf)

# Метрические методы
Метрические методы основаны на гипотезе компактности, суть которой состоит в том, что объекты с похожими признаковыми описаниями имеют похожие значения целевой переменной. Если эта гипотеза верна, то строить прогноз для нового объекта можно на основе близких к нему объектов из обучающей выборки — например, путем усреднения их ответов (для регрессии) или путем выбора наиболее популярного среди них класса (для классификации). Методы такого типа и называются метрическими. Они имеют несколько особенностей:

- Процедура обучения, по сути, отсутствует — достаточно лишь запомнить все объекты обучающей выборки
- Можно использовать метрику, учитывающую особенности конкретного набора данных — например, наличие категориальных (номинальных) признаков
- При правильном выборе метрики и достаточном размере обучающей выборки метрические алгоритмы показывают качество, близкое к оптимальному

Метрические методы чувствительны к масштабу признаков — так, если масштаб одного из признаков существенно превосходит масштабы остальных признаков, то их значения практически не будут влиять на ответы алгоритма. Поэтому важно производить масштабирование признаков. Обычно это делается путем вычитания среднего значения признака и деления на стандартное отклонение.

# Градиентные методы численной минимизации и алгоритм SG
Мы можем применять различные методы численной оптимизации для того, чтобы минимизировать наш аппроксимированный функционал, поскольку он теперь является непрерывной функцией или даже гладкой, в зависимости от того, какую функцию потерь мы использовали.
Самый, наверное, простой метод численной оптимизации — это метод **градиентного спуска**.
Он заключается в том, что сначала фиксируется некоторое начальное приближение для искомого вектора весов. Например, случайное. И затем делается последовательность градиентных шагов. То есть каждая итерация — это небольшое смещение вектора весов по антиградиенту.
Почему антиградиент? Градиент — это вектор, который показывает направление наискорейшего возрастания функции. Ну и, соответственно, минус этот вектор, или антиградиент, он показывает направление наискорейшего убывания.
То есть нам туда и надо идти, чтобы найти минимум функционала. Здесь возникает несколько проблем: проблема, будет ли этот метод сходиться; проблема выбора градиентного шага; проблема выбора начального приближения.
Так вот, идея сходимости, идея ускорения сходимости здесь заключается в том, чтобы не вычислять сумму сразу по всем объектам, а брать каждый объект... Ну обычно их берут в случайном порядке по одному. И после каждого объекта обновлять вектор весов.
Оказывается, что это приводит к существенному ускорению сходимости, это называется процедурой Роббинса–Монро и называется методом стохастической аппроксимации.
Процедура заключается в следующем: сначала инициализируется вектор весов, как это — мы чуть позже рассмотрим. Потом, при текущем положении вектора весов вычисляется оценка функционала качества на обучающей выборке, естественно, с нашей аппроксимированной функцией потерь, и затем начинается основной процесс.
На каждом шаге этого итерационного процесса мы выбираем объект и обучающие выборки случайным образом. Вычисляем значение функции потерь, обозначенного εi, и делаем градиентный шаг. А дальше, может быть, несколько нетривиальный ход, мы должны с учетом сделанной поправки к вектору весов переоценить значение функционала. Это нужно нам для того, чтобы понять, в какой момент нам останавливаться, когда значение функционала к чему-то сойдется или перестанет существенно меняться. Здесь использована формула экспоненциального скользящего среднего для того, чтобы подсчитать, ну пусть не точно значение функционала на всех объектах обучающей выборки, но по быстрой рекурентной формуле оценить среднее значение функционала, среднее значение функции потерь, которая получалась на последних итерациях.
Это тоже такой прием, который позволяет здесь не потерять вычислительную эффективность метода за счет вычисления функционала качества на всей обучающей выборке. 
Он часто используется при оптимизации, при конструировании критериев остановки. Итак, проблема. Нам после каждого шага по вектору w, который делается по одному объекту, поэтому делается он очень эффективно, хотелось бы оценить, насколько улучшилось качество классификации всей обучающей выборки по полученному обновленному вектору w. Конечно же, если мы начнем вычислять среднее по всей обучающей выборке, мы потеряем эффективность этого метода. Поэтому вот используется такая рекурентная формула. Она называется экспоненциальным скользящим средним, и проще всего ее объяснить, если привести ее аналогию с рекурентной формулой для вычисления среднего арифметического. Она приведена на слайде. Это очень простая формула, которая получается перегруппировкой слагаемых. Так вот, если в этой формуле 1 / m заменить на некоторую константу λ, то мы получим другой способ усреднения. И если расписать по полученной рекурентной формуле, что же за сумму мы вычисляем, то окажется, что это сумма всех значений εi-тых, но вес этих значений убывает по мере того, как это значение дальше остается в прошлом. То есть можно сказать, что это **темп забывания** тех ошибок, которые мы допускали на каждой итерации. Ну и можно оценить, что значение параметра λ, если мы его выберем, скажем, 1 поделить на 100, то это будет примерно эквивалентно тому, что мы усредняем значение функционала на ста последних объектов, которые мы брали для обучения в методе стохастического градиента.

# Линейные алгоритмы
Линейные алгоритмы — распространенный класс моделей, которые отличается своей простотой и скоростью работы. Их можно обучать за разумное время на очень больших объемах данных, и при этом они могут работать с любыми типами признаков — вещественными, категориальными, разреженными. В этом задании мы предлагаем вам воспользоваться персептроном — одним из простейших вариантов линейных моделей.

Как и в случае с метрическими методами, качество линейных алгоритмов зависит от некоторых свойств данных. В частности, признаки должны быть нормализованы, то есть иметь одинаковый масштаб. Если это не так, и масштаб одного признака сильно превосходит масштаб других, то качество может резко упасть.

Один из способов нормализации заключается в стандартизации признаков. Для этого берется набор значений признака на всех объектах, вычисляется их среднее значение и стандартное отклонение. После этого из всех значений признака вычитается среднее, и затем полученная разность делится на стандартное отклонение.

# Линейные методы
Линейные методы имеют несколько очень важных подвидов. Метод опорных векторов максимизирует отступы объектов, что тесно связано с минимизацией вероятности переобучения. При этом он позволяет очень легко перейти к построению нелинейной разделяющей поверхности благодаря ядровому переходу. Логистическая регрессия позволяет оценивать вероятности принадлежености классам, что оказывается полезным во многих прикладных задачах.

# Минимизация эмпирического риска
[Эмпирический риск](http://www.machinelearning.ru/wiki/index.php?title=%D0%AD%D0%BC%D0%BF%D0%B8%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D1%80%D0%B8%D1%81%D0%BA) (Empirical Risk) — это средняя величина ошибки алгоритма на обучающей выборке.


Метод минимизации эмпирического риска (Empirical Risk Minimization, ERM) — это общий подход к решению широкого класса задач обучения по прецедентам, в первую очередь — задач обучения с учителем, включая задачи классификации и регрессии.

#### Задача обучения по прецедентам
Пусть X — множество описаний объектов,  Y — множество допустимых ответов. Предполагается, что существует неизвестная целевая зависимость — отображение y^*: X -> Y, значения которой известны только на объектах конечной обучающей выборки X^m = {(x_1, y_1),...,(x_m,y_m)}.
Задача обучения по прецедентам состоит в том, чтобы построить алгоритм a: X -> Y, который приближал бы неизвестную целевую зависимость как на элементах выборки, так и на всём множестве X.

# Линейный классификатор
[Линейный классификатор](http://www.machinelearning.ru/wiki/index.php?title=%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80) — алгоритм классификации, основанный на построении линейной разделяющей поверхности. В случае двух классов разделяющей поверхностью является гиперплоскость, которая делит пространство признаков на два полупространства. В случае большего числа классов разделяющая поверхность кусочно-линейна.

# Машина опорных векторов (SVM)
[Машина опорных векторов](http://www.machinelearning.ru/wiki/index.php?title=SVM) — является одной из наиболее популярных методологий обучения по прецедентам, предложенной В. Н. Вапником и известной в англоязычной литературе под названием SVM (Support Vector Machine).


[habrahabr](https://habrahabr.ru/post/105220/)


Оптимальная разделяющая гиперплоскость. Понятие зазора между классами (margin). Случай линейной разделимости. Задача квадратичного программирования. Опорные векторы. Случай отсутствия линейной разделимости. Функции ядра (kernel functions), спрямляющее пространство, теорема Мерсера. Способы построения ядер. Примеры ядер. Сопоставление SVM и нейронной RBF-сети. Обучение SVM методом активных ограничений. SVM-регрессия.


Метод опорных векторов (Support Vector Machine, SVM) — один из видов линейных классификаторов. Функционал, который он оптимизирует, направлен на максимизацию ширины разделяющей полосы между классами. Из теории статистического обучения известно, что эта ширина тесно связана с обобщающей способностью алгоритма, а ее максимизация позволяет бороться с переобучением.


Метод опорных векторов имеет еще одну особенность. Если преобразовать его оптимизационную задачу, то окажется, что итоговый классификатор можно представить как взвешенную сумму скалярных произведений данного объекта на объекты обучающей выборки&

По сути, алгоритм делает предсказания на основе сходства нового объекта с объектами обучающей выборки. При этом, как правило, далеко не все коэффициенты оказываются ненулевыми. Это означает, что классификация делается на основе сходства лишь с частью обучающих объектов. Такие объекты называются **опорными**.

# Логистическая регрессия
[Логистическая регрессия](http://www.machinelearning.ru/wiki/index.php?title=%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F) является одним из статистических методов классификации с использованием линейного дискриминанта Фишера.


В отличие от обычной регрессии, в методе логистической регрессии не производится предсказание значения числовой переменной исходя из выборки исходных значений. Вместо этого, значением функции является вероятность того, что данное исходное значение принадлежит к определенному классу. Для простоты, давайте предположим, что у нас есть только два класса и вероятность, которую мы будем определять, вероятности того, что некоторое значение принадлежит классу "+". И конечно P_ = 1 - P+. Таким образом, результат логистической регрессии всегда находится в интервале [0, 1].

Основная идея логистической регрессии заключается в том, что пространство исходных значений может быть разделено линейной границей (т.е. прямой) на две соответствующих классам области. Итак, что же имеется ввиду под линейной границей? В случае двух измерений — это просто прямая линия без изгибов. В случае трех — плоскость, и так далее. Эта граница задается в зависимости от имеющихся исходных данных и обучающего алгоритма. Чтобы все работало, точки исходных данных должны разделяться линейной границей на две вышеупомянутых области. Если точки исходных данных удовлетворяют этому требованию, то их можно назвать линейно разделяемыми.

1. Логистическая регрессия — одно из статистических методов классификации с использованием линейного дискриминанта Фишера.
2. Значением функции является вероятность того, что данное исходное значение принадлежит к определенному классу.
3. Механизм обучения логистической регрессии старается максимизировать среднее значение.


Разница между SVM и логистической регрессией с L2-регуляризацией состоит в том, что в SMV используется кусочно-постоянная функция, а для логистической регрессии - логарифмическая.

# Линейная регрессия:

#### [Ридж-регрессия](http://www.machinelearning.ru/wiki/index.php?title=%D0%A0%D0%B8%D0%B4%D0%B6-%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F)
*Ридж-регрессия или гребневая регрессия* (англ. ridge regression) - это один из методов понижения размерности.
Часто его применяют для борьбы с переизбыточностью данных, когда независимые переменные коррелируют друг с другом (т.е. имеет место мультиколлинеарность).
Следствием этого является плохая обусловленность матрицы X^T X и неустойчивость оценок коэффициентов регрессии. Оценки, например, могут иметь неправильный знак или значения, которые намного превосходят те, которые приемлемы из физических или практических соображений.


Применение гребневой регрессии нередко оправдывают тем, что это практический приём, с помощью которого при желании можно получить меньшее значение среднего квадрата ошибки.


Метод стоит использовать, если:
- сильная обусловленность;
- сильно различаются собственные значения или некоторые из них близки к нулю;
- в матрице X есть почти линейно зависимые столбцы.


*Пример задачи*:
- Предположим признаки в задаче были плохо отобраны экспертами и в X присутствуют данные о длине, выраженные с сантиметрах и дюймах. Легко видеть, что эти данные линейно зависимы.

#### LASSO
Гребневая регрессия и лассо — это две техники регуляризации, которые применяются в линейных моделях классификация и регрессия для того, 
чтобы решить проблемы мультиколлинеарности и переобучения.


Сначала рассмотрим гребневую регрессию. Как мы с вами видели, увеличение вектора коэффициентов α — это и есть признак мультиколлинеарности. Поэтому здесь вводится дополнительное штрафное слагаемое к нашему основному функционалу, которое штрафует за избыточное увеличение нормы вектора коэффициентов. Фактически, возникают два критерия, один — тот, который был раньше из метода наименьших квадратов, и второй — это квадрат нормы весов, который должен быть минимизирован.


Гребневая регрессия и Лассо — это два метода, которые позволяют зажать вектор коэффициентов линейной модели так, чтобы у нас не проявлялась проблема мультиколлиниарности.
Но при этом Лассо обладает дополнительным интересным свойством обнулять некоторые веса признаков, тем самым выбрасывая признаки из модели.
Оба метода имеют параметр регуляризации, который можно также называть параметр селективности, потому что варьируя этот параметр в методе Лассо мы можем исключать больше или меньше признаков из модели.

 - Гребневая регрессия использует L2 регуляризатор
 - Метод LASSO использует L1 регуляризатор
 - Гребневая регрессия удобно вводится и интерпретируется через сингулярное разложение
 - Гребневая регрессия сокращает веса признаков
 - LASSO обнуляет веса признаков

# Метод главных компонент
[Метод главных компонент](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D1%8B%D1%85_%D0%BA%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82) (англ. principal component analysis, PCA) — один из основных способов уменьшить размерность данных, потеряв наименьшее количество информации. Изобретён Карлом Пирсоном в 1901 году.


[Метод главных компонент](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D1%8B%D1%85_%D0%BA%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82) решает задачу понижения размерности - он находит новые признаки, зависящие от старых. При этом целевая переменная никак не используется, поэтому речь не идет ни о регрессии, ни о классификации.

- Метод главных компонент позволяет приближать матрицу её низкоранговым разложением
- Для этого достаточно взять из SVD-разложения первые m сингулярных чисел и векторов матрицы
- Этот прием широко используется в анализе данных - в задачах регрессии, классификации, сжатия данных, обработки изображений

# Композиции алгоритмов

<img src="https://github.com/vanyaland/hse-yandex-introduction-to-machine-learning/blob/master/res/ensemble-learners.png"
width="634" height="356">

#### Bootstrap aggregating bagging
<img src="https://github.com/vanyaland/hse-yandex-introduction-to-machine-learning/blob/master/res/bootstrap-aggregating-bagging.png"
width="636" height="358">

#### Bagging example

<img src="https://github.com/vanyaland/hse-yandex-introduction-to-machine-learning/blob/master/res/bagging-example-1.png"
width="636" height="358">
<img src="https://github.com/vanyaland/hse-yandex-introduction-to-machine-learning/blob/master/res/bagging-example-2.png"
width="636" height="358">
<img src="https://github.com/vanyaland/hse-yandex-introduction-to-machine-learning/blob/master/res/bagging-example-3.png"
width="636" height="358">
<img src="https://github.com/vanyaland/hse-yandex-introduction-to-machine-learning/blob/master/res/bagging-example-4.png"
width="636" height="358">

#### Boosting

<img src="https://github.com/vanyaland/hse-yandex-introduction-to-machine-learning/blob/master/res/boosting-1.png"
width="636" height="358">
<img src="https://github.com/vanyaland/hse-yandex-introduction-to-machine-learning/blob/master/res/boosting-2.png"
width="636" height="358">

#### Bagging
 Рассмотрим один из самых известных методов повышения различности базовых алгоритмов.
 В этом методе базовые алгоритмы обучаются независимо друг от друга по случайным подвыборкам.
 Метод называется бэггинг — это искусственное слово, образованное от слов bootstrap aggregation. А bootsrap в статистике — это такой способ формирования выборки, когда выбирается ровно столько же объектов, сколько их исходно было, но объекты выбираются с повторениями.
То есть, как только вы выбрали случайный объект, вы его возвращаете обратно и можете выбрать его повторно. И при этом число объектов, которое вы выберете в выборку, оно будет составлять примерно 63 % от исходной выборки, и оставшаяся доля объектов ни разу не попадет в такую сэмплированную выборку. И вот по таким случайным подвыборкам, в которых некоторые объекты будут по несколько раз, но объем этой выборки равен объему исходной выборки, и предлагается обучать базовые алгоритмы.
Они будут обучаться совершенно независимо друг от друга — это некое преимущество, которое позволяет легко распараллеливать этот метод. Есть другой подход, который называется метод случайных подпространств.
Вы выбираете некоторое число n' — сколько признаков вы будете отбирать из числа исходных n признаков, и по полученным случайным подпространствам опять-таки можете строить базовый классификатор, причем нет никаких ограничений на использование тех или иных моделей классификаций в качестве базовых классификаторов. Эти два подхода можно совместить в одном алгоритме.


#### RF (random forest)
это множество решающих деревьев. В задаче регрессии их ответы усредняются, в задаче классификации принимается решение голосованием по большинству. Все деревья строятся независимо по следующей схеме:

- Выбирается подвыборка обучающей выборки размера *samplesize* (м.б. с возвращением) – по ней строится дерево (для каждого дерева — своя подвыборка).
- Для построения каждого расщепления в дереве просматриваем `max_features` случайных признаков (для каждого нового расщепления — свои случайные признаки).
- Выбираем наилучшие признак и расщепление по нему (по заранее заданному критерию). Дерево строится, как правило, до исчерпания выборки (пока в листьях не останутся представители только одного класса), но в современных реализациях есть параметры, которые ограничивают высоту дерева, число объектов в листьях и число объектов в подвыборке, при котором проводится расщепление.


*Число деревьев — `n_estimators`*

Чем больше деревьев, тем лучше качество, но время настройки и работы RF также пропорционально увеличиваются. Обратите внимание, что часто при увеличении n_estimators качество на обучающей выборке повышается (может даже доходить до 100%), а качество на тесте выходит на асимптоту (можно прикинуть, скольких деревьев Вам достаточно).


*Число признаков для выбора расщепления — `max_features`*


График качества на тесте от значения этого праметра унимодальный, на обучении он строго возрастает. При увеличении max_features увеличивается время построения леса, а деревья становятся «более однообразными». По умолчанию он равен sqrt(n) в задачах классификации и n/3 в задачах регрессии. Это самый важный параметр! Его настраивают в первую очередь (при достаточном числе деревьев в лесе).


*Максимальная глубина деревьев — `max_depth`*


Ясно, что чем меньше глубина, тем быстрее строится и работает RF. При увеличении глубины резко возрастает качество на обучении, но и на контроле оно, как правило, увеличивается. Рекомендуется использовать максимальную глубину (кроме случаев, когда объектов слишком много и получаются очень глубокие деревья, построение которых занимает значительное время). При использовании неглубоких деревьев изменение параметров, связанных с ограничением числа объектов в листе и для деления, не приводит к значимому эффекту (листья и так получаются «большими»). Неглубокие деревья рекомендуют использовать в задачах с большим числом шумовых объектов (выбросов).


**Cлучайный лес**. Это специальный случай бэггинга, когда в качестве базового семейства используются решающие деревья, при этом, в отличие от обычных способов построения решающих деревьев, вы здесь не используете усечение (или pruning).
Вообще, метод настроен на то, чтобы построить композицию как можно быстрее, чтобы можно было строить композиции по большим выборкам данных. Дальше построение дерева тоже производится весьма специфическим образом.
Когда вы выбираете признак для каждого внутреннего узла в этом решающем дереве, вы его выбираете не из всего множества n признаков, а из какого-то случайного подмножества, состоящего из k признаков. Причем, если дерево строится для классификаций, то рекомендуется брать k, равном корню квадратному из числа признаков, а если для регрессии — то число признаков делить на 3. Это эмпирические рекомендации.

Вот, оказывается, что если таким образом строить бэггинг над решающими деревьями, мы получим большое количество решающих деревьев, их простое голосование как раз и называется случайным лесом.
Оказалось, что этот алгоритм чрезвычайно эффективен, и он очень быстро обучается и очень хорошо решает практические задачи — вот как ни странно, несмотря на то, что столько было внесено случайности в процесс построения решающего леса, тем не менее, вот оказывается, что простое голосование делает из этих неточных, не очень хорошо построенных деревьев очень хороший агрегированный алгоритм классификации. 


*Random Forest* или «случайный лес» — это один из самых сильных методов машинного обучения. Он основан на бэггинге — на способе построения композиций классификаторов, при котором классификаторы обучаются независимо друг от друга.
Это позволяет легко распараллеливать этот метод, и далее используется простое голосование.
Бэггинг хорош еще и тем, что он позволяет вычислять оценки обобщающей способности (`out-of-bag`), использовать их для того, чтобы оптимизировать число базовых алгоритмов, оценивать степени важности признаков, подбирать параметры модели.
Но, тем не менее, `Random Forest` все же при решении практических задач обычно немного уступает другому композиционному методу, который называется градиентный бустинг.

# Нейронные сети
Нейронные сети позволяют находить сложные нелинейные разделяющие поверхности, благодаря чему широко используются в таких трудных задачах, как распознавание изображений и речи. В этом модуле мы изучим многослойные нейронные сети и их настройку с помощью метода обратного распространения ошибки.

# Кластеризация

### K-Means

- Алгоритм K-Means - пример метода обучения без учителя
- На вход алгоритму K-Means передаются объекты и количество кластеров *k*
- Положение центра кластера вычисляется как среднее всех объектов данного кластера

#### Недостатки K-Means

- Чувствительность к выбору начального приближения
- Необходимость задавать *k*

#### Способы устранения этих недостатков

- Эвристики для выбора начального приближения
- Мягкая кластеризация
- Мультистарт: несколько случайных инициализаций; выбор лучшей кластеризации по функционалу качества.
- Быстрые алгоритмы (*k-means++*, сэмплирование)
- Варьирование числа кластеров *k* в ходе итераций

### Иерархическая кластеризация

- K-Means и алгоритм Ланса-Уильяма решают задачу кластеризации
- В отличии от K-Means, в случае иерархической кластеризации необходимо вычислять расстояния между кластерами

#### Рекомендации и выводы

- Рекомендуется пользоваться расстоянием Уорда R^y
- Обычно строят несколько вариантов и выбирают лучший визуально по дендрограмме
- Определение числа кластеров - по максимуму |R_{t+1} - R_{t}|, тогда результирующее множество кластеров := C_{t}
