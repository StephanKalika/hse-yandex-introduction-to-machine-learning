# Решающие деревья

Решающие деревья относятся к классу логических методов. Их основная идея состоит в объединении определенного количества простых решающих правил, благодаря чему итоговый алгоритм является интерпретируемым. Как следует из названия, решающее дерево представляет собой бинарное дерево, в котором каждой вершине сопоставлено некоторое правило вида "j-й признак имеет значение меньше b". В листьях этого дерева записаны числа-предсказания. Чтобы получить ответ, нужно стартовать из корня и делать переходы либо в левое, либо в правое поддерево в зависимости от того, выполняется правило из текущей вершины или нет.

Одна из особенностей решающих деревьев заключается в том, что они позволяют получать важности всех используемых признаков. Важность признака можно оценить на основе того, как сильно улучшился критерий качества благодаря использованию этого признака в вершинах дерева.

#### Материалы

- [Подробнее про решающие деревья в sklearn](http://scikit-learn.org/stable/modules/tree.html)
- [Работа с пропущенными значениями в pandas](http://pandas.pydata.org/pandas-docs/stable/missing_data.html)
- [Подробнее о деревьях и их построении](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/lecture-notes/lecture07-trees.pdf)

# Метрические методы
Метрические методы основаны на гипотезе компактности, суть которой состоит в том, что объекты с похожими признаковыми описаниями имеют похожие значения целевой переменной. Если эта гипотеза верна, то строить прогноз для нового объекта можно на основе близких к нему объектов из обучающей выборки — например, путем усреднения их ответов (для регрессии) или путем выбора наиболее популярного среди них класса (для классификации). Методы такого типа и называются метрическими. Они имеют несколько особенностей:

- Процедура обучения, по сути, отсутствует — достаточно лишь запомнить все объекты обучающей выборки
- Можно использовать метрику, учитывающую особенности конкретного набора данных — например, наличие категориальных (номинальных) признаков
- При правильном выборе метрики и достаточном размере обучающей выборки метрические алгоритмы показывают качество, близкое к оптимальному

Метрические методы чувствительны к масштабу признаков — так, если масштаб одного из признаков существенно превосходит масштабы остальных признаков, то их значения практически не будут влиять на ответы алгоритма. Поэтому важно производить масштабирование признаков. Обычно это делается путем вычитания среднего значения признака и деления на стандартное отклонение.

# Градиентные методы численной минимизации и алгоритм SG
Мы можем применять различные методы численной оптимизации для того, чтобы минимизировать наш аппроксимированный функционал, поскольку он теперь является непрерывной функцией или даже гладкой, в зависимости от того, какую функцию потерь мы использовали.
Самый, наверное, простой метод численной оптимизации — это метод **градиентного спуска**.
Он заключается в том, что сначала фиксируется некоторое начальное приближение для искомого вектора весов. Например, случайное. И затем делается последовательность градиентных шагов. То есть каждая итерация — это небольшое смещение вектора весов по антиградиенту.
Почему антиградиент? Градиент — это вектор, который показывает направление наискорейшего возрастания функции. Ну и, соответственно, минус этот вектор, или антиградиент, он показывает направление наискорейшего убывания.
То есть нам туда и надо идти, чтобы найти минимум функционала. Здесь возникает несколько проблем: проблема, будет ли этот метод сходиться; проблема выбора градиентного шага; проблема выбора начального приближения.
Так вот, идея сходимости, идея ускорения сходимости здесь заключается в том, чтобы не вычислять сумму сразу по всем объектам, а брать каждый объект... Ну обычно их берут в случайном порядке по одному. И после каждого объекта обновлять вектор весов.
Оказывается, что это приводит к существенному ускорению сходимости, это называется процедурой Роббинса–Монро и называется методом стохастической аппроксимации.
Процедура заключается в следующем: сначала инициализируется вектор весов, как это — мы чуть позже рассмотрим. Потом, при текущем положении вектора весов вычисляется оценка функционала качества на обучающей выборке, естественно, с нашей аппроксимированной функцией потерь, и затем начинается основной процесс.
На каждом шаге этого итерационного процесса мы выбираем объект и обучающие выборки случайным образом. Вычисляем значение функции потерь, обозначенного εi, и делаем градиентный шаг. А дальше, может быть, несколько нетривиальный ход, мы должны с учетом сделанной поправки к вектору весов переоценить значение функционала. Это нужно нам для того, чтобы понять, в какой момент нам останавливаться, когда значение функционала к чему-то сойдется или перестанет существенно меняться. Здесь использована формула экспоненциального скользящего среднего для того, чтобы подсчитать, ну пусть не точно значение функционала на всех объектах обучающей выборки, но по быстрой рекурентной формуле оценить среднее значение функционала, среднее значение функции потерь, которая получалась на последних итерациях.
Это тоже такой прием, который позволяет здесь не потерять вычислительную эффективность метода за счет вычисления функционала качества на всей обучающей выборке. 
Он часто используется при оптимизации, при конструировании критериев остановки. Итак, проблема. Нам после каждого шага по вектору w, который делается по одному объекту, поэтому делается он очень эффективно, хотелось бы оценить, насколько улучшилось качество классификации всей обучающей выборки по полученному обновленному вектору w. Конечно же, если мы начнем вычислять среднее по всей обучающей выборке, мы потеряем эффективность этого метода. Поэтому вот используется такая рекурентная формула. Она называется экспоненциальным скользящим средним, и проще всего ее объяснить, если привести ее аналогию с рекурентной формулой для вычисления среднего арифметического. Она приведена на слайде. Это очень простая формула, которая получается перегруппировкой слагаемых. Так вот, если в этой формуле 1 / m заменить на некоторую константу λ, то мы получим другой способ усреднения. И если расписать по полученной рекурентной формуле, что же за сумму мы вычисляем, то окажется, что это сумма всех значений εi-тых, но вес этих значений убывает по мере того, как это значение дальше остается в прошлом. То есть можно сказать, что это **темп забывания** тех ошибок, которые мы допускали на каждой итерации. Ну и можно оценить, что значение параметра λ, если мы его выберем, скажем, 1 поделить на 100, то это будет примерно эквивалентно тому, что мы усредняем значение функционала на ста последних объектов, которые мы брали для обучения в методе стохастического градиента.
