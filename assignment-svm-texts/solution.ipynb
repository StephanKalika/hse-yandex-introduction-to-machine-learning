{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Введение\n",
    "\n",
    "Метод опорных векторов (Support Vector Machine, SVM) — один из видов линейных классификаторов. Функционал, который он оптимизирует, направлен на максимизацию ширины разделяющей полосы между классами. Из теории статистического обучения известно, что эта ширина тесно связана с обобщающей способностью алгоритма, а ее максимизация позволяет бороться с переобучением.\n",
    "\n",
    "Одна из причин популярности линейных методов заключается в том, что они хорошо работают на разреженных данных. Так называются выборки с большим количеством признаков, где на каждом объекте большинство признаков равны нулю. Разреженные данные возникают, например, при работе с текстами. Дело в том, что текст удобно кодировать с помощью \"мешка слов\" — формируется столько признаков, сколько всего уникальных слов встречается в текстах, и значение каждого признака равно числу вхождений в документ соответствующего слова. Ясно, что общее число различных слов в наборе текстов может достигать десятков тысяч, и при этом лишь небольшая их часть будет встречаться в одном конкретном тексте.\n",
    "\n",
    "Можно кодировать тексты хитрее, и записывать не количество вхождений слова в текст, а TF-IDF. Это показатель, который равен произведению двух чисел: TF (term frequency) и IDF (inverse document frequency). Первая равна отношению числа вхождений слова в документ к общей длине документа. Вторая величина зависит от того, в скольки документах выборки встречается это слово. Чем больше таких документов, тем меньше IDF. Таким образом, TF-IDF будет иметь высокое значение для тех слов, которые много раз встречаются в данном документе, и редко встречаются в остальных.\n",
    "\n",
    "### Данные\n",
    "\n",
    "Как мы уже говорили выше, линейные методы часто применяются для решения различных задач анализа текстов. В этом задании мы применим метод опорных векторов для определения того, к какой из тематик относится новость: атеизм или космос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Загрузите объекты из новостного датасета 20 newsgroups, относящиеся к категориям \"космос\" и \"атеизм\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "newgroups = datasets.fetch_20newsgroups(subset='all', categories=['alt.atheism', 'sci.space'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После выполнения этого кода массив с текстами будет находиться в поле newsgroups.data, номер класса — в поле newsgroups.target.\n",
    "\n",
    "Одна из сложностей работы с текстовыми данными состоит в том, что для них нужно построить числовое представление. Одним из способов нахождения такого представления является вычисление TF-IDF. В Scikit-Learn это реализовано в классе sklearn.feature_extraction.text.TfidfVectorizer. Преобразование обучающей выборки нужно делать с помощью функции fit_transform, тестовой — с помощью transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: 9051467f@levels.unisa.edu.au (The Desert Brat)\\nSubject: Re: Keith Schneider - Stealth Poster?\\nOrganization: Cured, discharged\\nLines: 24\\n\\nIn article <1pa0f4INNpit@gap.caltech.edu>, keith@cco.caltech.edu (Keith Allan Schneider) writes:\\n\\n> But really, are you threatened by the motto, or by the people that use it?\\n\\nEvery time somone writes something and says it is merely describing the norm,\\nit is infact re-inforcing that norm upon those programmed not to think for\\nthemselves. The motto is dangerous in itself, it tells the world that every\\n*true* American is god-fearing, and puts down those who do not fear gods. It\\ndoesn\\'t need anyone to make it dangerous, it does a good job itself by just\\nexisting on your currency.\\n\\n> keith\\n\\nThe Desert Brat\\n-- \\nJohn J McVey, Elc&Eltnc Eng, Whyalla, Uni S Australia,    ________\\n9051467f@levels.unisa.edu.au      T.S.A.K.C.            \\\\/Darwin o\\\\\\nFor replies, mail to whjjm@wh.whyalla.unisa.edu.au      /\\\\________/\\nDisclaimer: Unisa hates my opinions.                       bb  bb\\n+------------------------------------------------------+-----------------------+\\n|\"It doesn\\'t make a rainbow any less beautiful that we | \"God\\'s name is smack  |\\n|understand the refractive mechanisms that chance to   | for some.\"            |\\n|produce it.\" - Jim Perry, perry@dsinc.com             |    - Alice In Chains  |\\n+------------------------------------------------------+-----------------------+\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newgroups.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newgroups.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'sci.space']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newgroups.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Вычислите TF-IDF-признаки для всех текстов. Обратите внимание, что в этом задании мы предлагаем вам вычислить TF-IDF по всем данным. При таком подходе получается, что признаки на обучающем множестве используют информацию из тестовой выборки — но такая ситуация вполне законна, поскольку мы не используем значения целевой переменной из теста. На практике нередко встречаются ситуации, когда признаки объектов тестовой выборки известны на момент обучения, и поэтому можно ими пользоваться при обучении алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12328)\t0.0137045393774\n",
      "  (0, 3083)\t0.183545829049\n",
      "  (0, 16212)\t0.130870716213\n",
      "  (0, 26748)\t0.358641401851\n",
      "  (0, 10446)\t0.0877895428146\n",
      "  (0, 5173)\t0.147007441189\n",
      "  (0, 25602)\t0.113127021266\n",
      "  (0, 9436)\t0.160322175265\n",
      "  (0, 6206)\t0.183545829049\n",
      "  (0, 24745)\t0.0137045393774\n",
      "  (0, 21441)\t0.0319711500148\n",
      "  (0, 15606)\t0.179738178431\n",
      "  (0, 22911)\t0.105890061373\n",
      "  (0, 24461)\t0.0896603504628\n",
      "  (0, 20381)\t0.065773758988\n",
      "  (0, 19110)\t0.0143081539732\n",
      "  (0, 8823)\t0.0896603504628\n",
      "  (0, 9768)\t0.0973296270647\n",
      "  (0, 16346)\t0.0137275657721\n",
      "  (0, 1668)\t0.0532164165719\n",
      "  (0, 14361)\t0.0444677816001\n",
      "  (0, 4890)\t0.0212421598026\n",
      "  (0, 1191)\t0.106828889895\n",
      "  (0, 12512)\t0.0593325757435\n",
      "  (0, 6741)\t0.0958731456593\n",
      "  :\t:\n",
      "  (1785, 8616)\t0.0961857077738\n",
      "  (1785, 11782)\t0.055635809034\n",
      "  (1785, 10058)\t0.0742115230561\n",
      "  (1785, 970)\t0.041884777141\n",
      "  (1785, 16405)\t0.0559553567536\n",
      "  (1785, 28298)\t0.0641466708717\n",
      "  (1785, 8301)\t0.0655664206707\n",
      "  (1785, 13477)\t0.0690845681599\n",
      "  (1785, 11783)\t0.0462980883169\n",
      "  (1785, 8620)\t0.111271618068\n",
      "  (1785, 4291)\t0.0510365396952\n",
      "  (1785, 8629)\t0.0742115230561\n",
      "  (1785, 16514)\t0.126996623802\n",
      "  (1785, 12602)\t0.28544325907\n",
      "  (1785, 18927)\t0.148423046112\n",
      "  (1785, 19343)\t0.0742115230561\n",
      "  (1785, 11465)\t0.0742115230561\n",
      "  (1785, 18099)\t0.0742115230561\n",
      "  (1785, 17085)\t0.222634569168\n",
      "  (1785, 6967)\t0.161118706891\n",
      "  (1785, 16314)\t0.0838225869731\n",
      "  (1785, 25655)\t0.0805593534453\n",
      "  (1785, 8638)\t0.176843712624\n",
      "  (1785, 12224)\t0.176843712624\n",
      "  (1785, 8639)\t0.088421856312\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(newgroups.data) # count tf-idf\n",
    "print(X)\n",
    "\n",
    "y = newgroups.target\n",
    "feature_map = vectorizer.get_feature_names() # look for words with ith feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Подберите минимальный лучший параметр C из множества [10^-5, 10^-4, ... 10^4, 10^5] для SVM с линейным ядром (kernel='linear') при помощи кросс-валидации по 5 блокам. Укажите параметр random_state=241 и для SVM, и для KFold. В качестве меры качества используйте долю верных ответов (accuracy).\n",
    "\n",
    "Подбор параметров удобно делать с помощью класса sklearn.grid_search.GridSearchCV\n",
    "\n",
    "Первым аргументом в GridSearchCV передается классификатор, для которого будут подбираться значения параметров, вторым — словарь (dict), задающий сетку параметров для перебора. После того, как перебор окончен, можно проанализировать значения качества для всех значений параметров и выбрать наилучший вариант:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=241, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=241, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': array([  1.00000e-05,   1.00000e-04,   1.00000e-03,   1.00000e-02,\n",
       "         1.00000e-01,   1.00000e+00,   1.00000e+01,   1.00000e+02,\n",
       "         1.00000e+03,   1.00000e+04,   1.00000e+05])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "clf = SVC(kernel='linear', random_state=241)\n",
    "gs = GridSearchCV(clf, C_grid, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Обучите SVM по всей выборке с оптимальным параметром C, найденным на предыдущем шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.552631578947 {'C': 1.0000000000000001e-05}\n",
      "0.552631578947 {'C': 0.0001}\n",
      "0.552631578947 {'C': 0.001}\n",
      "0.552631578947 {'C': 0.01}\n",
      "0.950167973124 {'C': 0.10000000000000001}\n",
      "0.993281075028 {'C': 1.0}\n",
      "0.993281075028 {'C': 10.0}\n",
      "0.993281075028 {'C': 100.0}\n",
      "0.993281075028 {'C': 1000.0}\n",
      "0.993281075028 {'C': 10000.0}\n",
      "0.993281075028 {'C': 100000.0}\n",
      "\n",
      "-------------------------------\n",
      "Best:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=241, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "for accuracy in gs.grid_scores_:\n",
    "    print(accuracy.mean_validation_score, accuracy.parameters) # Оценка качества по кросс-валидации / Значения параметров\n",
    "    \n",
    "print('\\n-------------------------------\\nBest: ', gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=241, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Найдите 10 слов с наибольшим абсолютным значением веса (веса хранятся в поле coef_ у svm.SVC). Они являются ответом на это задание. Укажите эти слова через запятую или пробел, в нижнем регистре, в лексикографическом порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.2546899512384038, 'atheism'), (1.2491800073760075, 'atheists'), (1.130612344664901, 'bible'), (1.9203794002294938, 'god'), (1.0970936466401482, 'keith'), (1.2016111817520696, 'moon'), (1.13908083789883, 'religion'), (1.0293069271856938, 'sci'), (1.1801315951388633, 'sky'), (2.6631647884797105, 'space')]\n"
     ]
    }
   ],
   "source": [
    "weights = np.absolute(clf.coef_.toarray())\n",
    "\n",
    "max_weights = sorted(zip(weights[0], feature_map))[-10:]\n",
    "max_weights.sort(key=lambda x: x[1])\n",
    "print(max_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('submission.txt', 'w')\n",
    "for w, c in max_weights[:-1]:\n",
    "    f.write(c)\n",
    "    f.write(',')\n",
    "f.write(max_weights[-1][1])\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
