{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Введение\n",
    "\n",
    "Логистическая регрессия — один из видов линейных классификаторов. Одной из ее особенностей является возможность оценивания вероятностей классов, тогда как большинство линейных классификаторов могут выдавать только номера классов.\n",
    "\n",
    "Логистическая регрессия использует достаточно сложный функционал качества, который не допускает записи решения в явном виде (в отличие от, например, линейной регрессии). Тем не менее, логистическую регрессию можно настраивать с помощью градиентного спуска.\n",
    "\n",
    "Линейные методы могут переобучаться и давать плохое качество из-за различных проблем в данных: мультиколлинеарности, зашумленности и т.д. Чтобы избежать этого, следует использовать регуляризацию — она позволяет понизить сложность модели и не допустить переобучения. Сила регуляризации определяется коэффициентом C.\n",
    "\n",
    "#### Реализация в Scikit-Learn\n",
    "\n",
    "В этом задании мы предлагаем вам самостоятельно реализовать градиентный спуск.\n",
    "\n",
    "В качестве метрики качества будем использовать AUC-ROC (Area Under ROC-Curve). Она предназначена для алгоритмов бинарной классификации, выдающих оценку принадлежности объекта к одному из классов. По сути, значение этой метрики является агрегацией показателей качества всех алгоритмов, которые можно получить, выбирая какой-либо порог для оценки принадлежности.\n",
    "\n",
    "В Scikit-Learn метрика AUC реализована функцией sklearn.metrics.roc_auc_score. В качестве первого аргумента ей передается вектор истинных ответов, в качестве второго — вектор с оценками принадлежности объектов к первому классу.\n",
    "\n",
    "#### Материалы\n",
    "\n",
    "- [Подробнее о логистической регрессии и предсказании вероятностей с ее помощью](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/lecture-notes/lecture05-linclass.pdf)\n",
    "- [Подробнее о градиентах и градиентном спуске](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/lecture-notes/lecture02-linregr.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error as rms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Загрузите данные из файла data-logistic.csv. Это двумерная выборка, целевая переменная на которой принимает значения -1 или 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data-logistic.csv', header=None)\n",
    "x = data.loc[:, 1:]\n",
    "y = data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Убедитесь, что выше выписаны правильные формулы для градиентного спуска. Обратите внимание, что мы используем полноценный градиентный спуск, а не его стохастический вариант!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 0.1\n",
    "ERROR = 1e-5\n",
    "\n",
    "def sigma_y(i, w1, w2):\n",
    "    return 1. / (1. + exp(-y[i] * (w1*x[1][i] + w2*x[2][i])))\n",
    "\n",
    "def delta_for_w(w_index, w1, w2, C):\n",
    "    addition = sum((\n",
    "        y[i] * x[w_index][i] * (1. - sigma_y(i, w1, w2)) for i in np.arange(0, len(y))\n",
    "    ))\n",
    "    addition *= K / len(y)\n",
    "    addition -= K * C * (w1 if w_index == 1 else w2)\n",
    "    \n",
    "    return addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Реализуйте градиентный спуск для обычной и L2-регуляризованной (с коэффициентом регуляризации 10) логистической регрессии. Используйте длину шага k=0.1. В качестве начального приближения используйте вектор (0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_regressor(C, iterations_remaining=10000):\n",
    "    changed_w1, changed_w2 = 0., 0.\n",
    "    while iterations_remaining:\n",
    "        iterations_remaining -= 1\n",
    "        w1, w2 = changed_w1, changed_w2\n",
    "        changed_w1 = w1 + delta_for_w(1, w1, w2, C)\n",
    "        changed_w2 = w2 + delta_for_w(2, w1, w2, C)\n",
    "        if np.sqrt(rms([w1, w2], [changed_w1, changed_w2])) <= ERROR:\n",
    "            break\n",
    "    return changed_w1, changed_w2\n",
    "\n",
    "def sigma(xi, w1, w2):\n",
    "    return 1. / (1 + np.exp(-w1 * xi[1] - w2 * xi[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Запустите градиентный спуск и доведите до сходимости (евклидово расстояние между векторами весов на соседних итерациях должно быть не больше 1e-5). Рекомендуется ограничить сверху число итераций десятью тысячами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.287683251283 0.0921020117342 0.0285587545462 0.0247801372497\n"
     ]
    }
   ],
   "source": [
    "w1, w2 = gradient_regressor(0.)\n",
    "l2w1, l2w2 = gradient_regressor(10.)\n",
    "\n",
    "print(w1, w2, l2w1, l2w2)\n",
    "\n",
    "scores = x.apply(lambda xi: sigma(xi, w1, w2), axis=1)\n",
    "l2scores = x.apply(lambda xi: sigma(xi, l2w1, l2w2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Какое значение принимает AUC-ROC на обучении без регуляризации и при ее использовании? Эти величины будут ответом на задание. В качестве ответа приведите два числа через пробел. Обратите внимание, что на вход функции roc_auc_score нужно подавать оценки вероятностей, подсчитанные обученным алгоритмом. Для этого воспользуйтесь сигмоидной функцией: a(x) = 1 / (1 + exp(-w1 x1 - w2 x2))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926857142857\n",
      "0.936285714286\n"
     ]
    }
   ],
   "source": [
    "auc_score = roc_auc_score(y, scores)\n",
    "l2_auc_score = roc_auc_score(y, l2scores)\n",
    "\n",
    "print(auc_score)\n",
    "print(l2_auc_score)\n",
    "\n",
    "f = open('submission.txt', 'w')\n",
    "f.write(str(auc_score) + ' ' + str(l2_auc_score))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
