{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('features.csv', index_col = 'match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим признаки, которых нет в тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['duration', 'tower_status_radiant', 'tower_status_dire', 'barracks_status_radiant', \n",
    "                   'barracks_status_dire']\n",
    "for column in columns_to_drop:\n",
    "    df.drop(column, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Проверьте выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем признаки с пропусками в данных. Не будем использовать функцию count(), а автоматически найдем имена признаков с пропусками):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_blood_time', 'first_blood_team', 'first_blood_player1', 'first_blood_player2', 'radiant_bottle_time', 'radiant_courier_time', 'radiant_flying_courier_time', 'radiant_first_ward_time', 'dire_bottle_time', 'dire_courier_time', 'dire_flying_courier_time', 'dire_first_ward_time']\n"
     ]
    }
   ],
   "source": [
    "missing_data_columns = list(filter(lambda column: df[column].isna().values.any(), df.columns))\n",
    "\n",
    "print(missing_data_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые два признака с пропусками `first_blood_time` и `first_blood_team`. Пропуски в них логичны, т.к. не обязательно в каждой игре \"первая кровь\" происходила в течение первых 5 минут игры, про которые у нас есть данные.\n",
    "\n",
    "В целом, можно заметить, что пропуски связаны с событиями \"первая кровь\" и \"приобретение предметов\". Это можно легко объяснить именно тем, что эти события просто не произошли за первые пять минут игры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Замените пропуски на нули с помощью функции fillna(). На самом деле этот способ является предпочтительным для логистической регрессии, поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание. Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не будем заменять пропуски на 0, т.к. это не логично. Эти признаки - время, а значит если мы заменим пустые значения в них на 0, это будет означать, что события произошли в самом начале игры. Но в действительности они не произошли. Так что заменим их на -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Какой столбец содержит целевую переменную? Запишите его название."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно документации - `radiant_win`. Вот его значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(df['radiant_win'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице \"объекты-признаки\". Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold), не забудьте перемешать при этом выборку (shuffle=True), поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим матрицы c признаками для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = df.as_matrix(columns = df.columns.difference(['radiant_win']))\n",
    "y = np.ravel(df.as_matrix(columns = ['radiant_win']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим градиентный бустинг и посмотрим его качество с помощью AUC-ROC и кросс-валидации для разного числа деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10, roc_auc = 0.6647663489746313, time = 0:00:39.457429\n",
      "n_estimators = 20, roc_auc = 0.6825735847213263, time = 0:01:10.378600\n",
      "n_estimators = 30, roc_auc = 0.6901836602702403, time = 0:01:45.939393\n",
      "n_estimators = 40, roc_auc = 0.6944579347951023, time = 0:02:24.659465\n",
      "n_estimators = 50, roc_auc = 0.6978675524096297, time = 0:02:47.372763\n",
      "n_estimators = 60, roc_auc = 0.7005126037101042, time = 0:04:17.478760\n",
      "n_estimators = 70, roc_auc = 0.7024448631651243, time = 0:07:04.563176\n",
      "n_estimators = 80, roc_auc = 0.7041253821974692, time = 0:07:24.371417\n",
      "n_estimators = 90, roc_auc = 0.7056720928469578, time = 0:04:33.210721\n",
      "n_estimators = 100, roc_auc = 0.7067734299816308, time = 0:05:24.324671\n",
      "n_estimators = 110, roc_auc = 0.7076780369721887, time = 0:05:43.466773\n",
      "n_estimators = 120, roc_auc = 0.7085808454715753, time = 0:06:31.946728\n",
      "n_estimators = 130, roc_auc = 0.7094237562967745, time = 0:07:39.270207\n",
      "n_estimators = 140, roc_auc = 0.7101196525024956, time = 0:07:48.221477\n",
      "n_estimators = 150, roc_auc = 0.710838887704501, time = 0:08:33.673056\n",
      "n_estimators = 160, roc_auc = 0.7116509215206753, time = 0:09:09.280132\n",
      "n_estimators = 170, roc_auc = 0.7123613768478453, time = 0:09:28.475370\n",
      "n_estimators = 180, roc_auc = 0.7129614318439201, time = 0:10:15.341473\n",
      "n_estimators = 190, roc_auc = 0.7135981998404077, time = 0:12:48.424384\n",
      "n_estimators = 200, roc_auc = 0.714139745421826, time = 0:18:16.559695\n",
      "n_estimators = 210, roc_auc = 0.7148172661184822, time = 0:10:18.446740\n",
      "n_estimators = 220, roc_auc = 0.7153807627222983, time = 0:11:15.124155\n",
      "n_estimators = 230, roc_auc = 0.7158992306384716, time = 0:16:50.329535\n",
      "n_estimators = 240, roc_auc = 0.7161801051882831, time = 0:13:59.267918\n",
      "n_estimators = 250, roc_auc = 0.7165190115257408, time = 0:13:51.337540\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle = True)\n",
    "data_split = list(kfold.split(x))\n",
    "\n",
    "roc_aucs = []\n",
    "working_times = []\n",
    "n_estimators = list(range(10, 251, 10))\n",
    "\n",
    "def measure_gbc(n, learning_rate = 0.1, max_depth = 3):\n",
    "    n_roc_aucs = []\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for train_index, test_index in data_split:\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        gbclf = GradientBoostingClassifier(n_estimators = n, learning_rate = learning_rate,\n",
    "                                           max_depth = max_depth)\n",
    "        gbclf.fit(x_train, y_train)\n",
    "        y_score = gbclf.predict_proba(x_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_true = y_test, y_score = y_score)\n",
    "        n_roc_aucs.append(roc_auc)\n",
    "\n",
    "    roc_auc = np.mean(n_roc_aucs)\n",
    "    working_time = datetime.datetime.now() - start_time\n",
    "    return roc_auc, working_time\n",
    "    \n",
    "for n in n_estimators:\n",
    "    roc_auc, working_time = measure_gbc(n)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    working_times.append(working_time)\n",
    "    print(f\"n_estimators = {n}, roc_auc = {roc_auc}, time = {working_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Анализ результатов работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае `30` деревьев работа алгоритма заняла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:45.939393\n"
     ]
    }
   ],
   "source": [
    "index = n_estimators.index(30)\n",
    "print(working_times[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом алгоритм показал следующее значение AUC-ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69018366027\n"
     ]
    }
   ],
   "source": [
    "print(roc_aucs[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем график зависимости AUC-ROC от числа деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x100f897f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.title('AUC-ROC - N Estimators Chart')\n",
    "plt.plot(n_estimators, roc_aucs, color = 'green', linestyle = 'solid', \n",
    "         marker = 'o', linewidth = 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как следует из графика, прирост качества замедляется по мере увеличения числа деревьев. Не смотря на это, использование более 30 деревьев вполне оправданно. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем разобраться что можно сделать, чтобы ускорить обучение на большом количестве дереьвев. У градиентного бустинга есть три основных параметра для тюнинга: количество деревьев, скорость обучения и максимальная глубина деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим влияние скорости обучения на время обучения алгоритма при числе деревьев равном 60:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1, roc_auc = 0.7006716211176018, time = 0:05:58.737985\n",
      "learning_rate = 0.5, roc_auc = 0.7094754620355662, time = 0:04:14.171295\n",
      "learning_rate = 0.3, roc_auc = 0.71038435911665, time = 0:03:03.764492\n",
      "learning_rate = 0.2, roc_auc = 0.7069728504555586, time = 0:03:04.700608\n",
      "learning_rate = 0.1, roc_auc = 0.7005126037101042, time = 0:03:04.485157\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in [1, 0.5, 0.3, 0.2, 0.1]:\n",
    "    roc_auc, working_time = measure_gbc(60, learning_rate = learning_rate)\n",
    "    print(f\"learning_rate = {learning_rate}, roc_auc = {roc_auc}, time = {working_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, время работы алгоритма существенно не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим влияние максимальной глубины деревьев на скорость обучения при числе деревьев равном 60:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 3, roc_auc = 0.7005126037101042, time = 0:03:01.369567\n",
      "max_depth = 2, roc_auc = 0.6950462090663883, time = 0:01:55.518514\n",
      "max_depth = 1, roc_auc = 0.6820302171548914, time = 0:00:58.586370\n"
     ]
    }
   ],
   "source": [
    "for max_depth in [3, 2, 1]:\n",
    "    roc_auc, working_time = measure_gbc(60, max_depth = max_depth)\n",
    "    print(f\"max_depth = {max_depth}, roc_auc = {roc_auc}, time = {working_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшение максимальной глубины деревьев до 2 заметно ускоряет обучение, при это качество уменьшается незначительно. Поэтому для ускорения обучения на большом количестве деревьев можно уменьшать их максимальную глубину."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим и подготовим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('features.csv', index_col = 'match_id')\n",
    "\n",
    "columns_to_drop = ['duration', 'tower_status_radiant', 'tower_status_dire', 'barracks_status_radiant', \n",
    "                   'barracks_status_dire']\n",
    "for column in columns_to_drop:\n",
    "    df.drop(column, axis = 1, inplace = True)\n",
    "    \n",
    "df.fillna(-1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала проведём нормализацию признаков, т.к. линейные методы чувствительны к масштабу исходных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "heroes_ids_columns = ['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                      'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "cat_columns = ['lobby_type'] + heroes_ids_columns\n",
    "columns_to_scale = df.columns.difference(['radiant_win', 'start_time'] + cat_columns)\n",
    "\n",
    "data = df.as_matrix(columns = columns_to_scale)\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "for i, column in enumerate(columns_to_scale):\n",
    "    df[column] = data[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим матрицы с признаками для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.as_matrix(columns = df.columns.difference(['radiant_win', 'start_time']))\n",
    "y = np.ravel(df.as_matrix(columns = ['radiant_win']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим логистическую регрессию для разных значений параметра регуляризации C. Будем использовать ту же кросс-валидацию, что и для градиентного бустинга чтобы можно было сравнивать значения AUC-ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1e-06, roc_auc = 0.6600091722088369, time = 0:00:03.592894\n",
      "C = 1e-05, roc_auc = 0.6957045993305769, time = 0:00:04.611708\n",
      "C = 0.0001, roc_auc = 0.7109203000985014, time = 0:00:08.761236\n",
      "C = 0.001, roc_auc = 0.7157764203388917, time = 0:00:15.511621\n",
      "C = 0.01, roc_auc = 0.7159212130720893, time = 0:00:19.348066\n",
      "C = 0.1, roc_auc = 0.7158813480992721, time = 0:00:22.016497\n",
      "C = 1.0, roc_auc = 0.7158792164517782, time = 0:00:21.644576\n",
      "C = 10.0, roc_auc = 0.715881121129817, time = 0:00:19.587485\n",
      "C = 100.0, roc_auc = 0.7158826662574965, time = 0:00:20.438621\n",
      "C = 1000.0, roc_auc = 0.71587648053025, time = 0:00:22.011590\n",
      "C = 10000.0, roc_auc = 0.7158775194090932, time = 0:00:22.067916\n",
      "C = 100000.0, roc_auc = 0.7158777270341311, time = 0:00:21.931253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "roc_aucs = []\n",
    "cs = np.power(10.0, np.arange(-6, 6))\n",
    "\n",
    "def measure_lr(c):\n",
    "    n_roc_aucs = []\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    for train_index, test_index in data_split:\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        lr = LogisticRegression(C = c)\n",
    "        lr.fit(x_train, y_train)\n",
    "        y_score = lr.predict_proba(x_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_true = y_test, y_score = y_score)\n",
    "        n_roc_aucs.append(roc_auc)\n",
    "\n",
    "    roc_auc = np.mean(n_roc_aucs)\n",
    "    working_time = datetime.datetime.now() - start_time\n",
    "    return roc_auc, working_time\n",
    "    \n",
    "for c in cs:\n",
    "    roc_auc, working_time = measure_lr(c)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    print(f\"C = {c}, roc_auc = {roc_auc}, time = {working_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия показывает высокое качество сравнимое с градиентным бустингом на числе дервьев более 250. При этом скорость обучения существенно выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график зависимости качества логистической регрессии AUC-ROC от логарифма параметра регуляризации С:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108e9ee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "plt.figure()\n",
    "plt.title('AUC-ROC - C Chart')\n",
    "plt.plot(list(map(lambda v: math.log10(v), cs)), roc_aucs, color = 'green', linestyle = 'solid', \n",
    "         marker = 'o', linewidth = 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графика, параметр регуляризации С в данном случае не оказывает существенного влияния на качество логистической регрессии. Наилучшее качество получается при C = 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим категориальные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.copy(deep = True)\n",
    "for column in cat_columns:\n",
    "    df_cat.drop(column, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим матрицы с данными для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_cat.as_matrix(columns = df_cat.columns.difference(['radiant_win', 'start_time']))\n",
    "y = np.ravel(df_cat.as_matrix(columns = ['radiant_win']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим как удаление категориальных признаков повлияло на логистическую регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1e-06, roc_auc = 0.6905443007976004, time = 0:00:01.954221\n",
      "C = 1e-05, roc_auc = 0.6964099852845461, time = 0:00:02.392518\n",
      "C = 0.0001, roc_auc = 0.710948103093101, time = 0:00:04.011072\n",
      "C = 0.001, roc_auc = 0.715784672758926, time = 0:00:07.237495\n",
      "C = 0.01, roc_auc = 0.715919058697688, time = 0:00:09.811781\n",
      "C = 0.1, roc_auc = 0.7158812093401765, time = 0:00:10.354296\n",
      "C = 1.0, roc_auc = 0.7158764791228169, time = 0:00:10.398416\n",
      "C = 10.0, roc_auc = 0.7158760236316225, time = 0:00:10.479774\n",
      "C = 100.0, roc_auc = 0.7158760236486514, time = 0:00:10.414042\n",
      "C = 1000.0, roc_auc = 0.7158760067047885, time = 0:00:10.293989\n",
      "C = 10000.0, roc_auc = 0.7158760067034378, time = 0:00:10.350027\n",
      "C = 100000.0, roc_auc = 0.7158760067034378, time = 0:00:10.413510\n"
     ]
    }
   ],
   "source": [
    "roc_aucs = []\n",
    "\n",
    "for c in cs:\n",
    "    roc_auc, working_time = measure_lr(c)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    print(f\"C = {c}, roc_auc = {roc_auc}, time = {working_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После удаления категориальных признаков качество практически не изменилось, значит они в том виде, что мы их использовали, не имеют существенного значения для качества модели. Лучшее качество по-прежнему достигается при C = 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько всего идентификаторов героев существует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "heroes_ids = np.unique(list(map(lambda c: df[c].unique(), heroes_ids_columns)))\n",
    "print(len(heroes_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим матрицу таких признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.max(heroes_ids)\n",
    "x_pick = np.zeros((df.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(df.index):\n",
    "    for p in range(5):\n",
    "        x_pick[i, df.loc[match_id, 'r%d_hero' % (p+1)] - 1] = 1\n",
    "        x_pick[i, df.loc[match_id, 'd%d_hero' % (p+1)] - 1] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим ее к набору данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    df_cat[f\"Hero{i}\"] = x_pick[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим матрицы с данными для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_cat.as_matrix(columns = df_cat.columns.difference(['radiant_win', 'start_time']))\n",
    "y = np.ravel(df_cat.as_matrix(columns = ['radiant_win']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как это преобразование повлияло на обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1e-06, roc_auc = 0.693050718738124, time = 0:00:02.651030\n",
      "C = 1e-05, roc_auc = 0.7006059450612709, time = 0:00:03.089203\n",
      "C = 0.0001, roc_auc = 0.724687038382984, time = 0:00:05.287139\n",
      "C = 0.001, roc_auc = 0.7457215406423588, time = 0:00:09.635899\n",
      "C = 0.01, roc_auc = 0.7511369536477372, time = 0:00:15.824552\n",
      "C = 0.1, roc_auc = 0.7513495315423777, time = 0:00:21.162533\n",
      "C = 1.0, roc_auc = 0.7513326614865894, time = 0:00:22.194791\n",
      "C = 10.0, roc_auc = 0.7513303352994122, time = 0:00:22.363398\n",
      "C = 100.0, roc_auc = 0.7513298840157099, time = 0:00:22.324373\n",
      "C = 1000.0, roc_auc = 0.7513300195667766, time = 0:00:22.302132\n",
      "C = 10000.0, roc_auc = 0.7513299602424944, time = 0:00:22.214095\n",
      "C = 100000.0, roc_auc = 0.7513299284793127, time = 0:00:22.463800\n"
     ]
    }
   ],
   "source": [
    "roc_aucs = []\n",
    "\n",
    "for c in cs:\n",
    "    roc_auc, working_time = measure_lr(c)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    print(f\"C = {c}, roc_auc = {roc_auc}, time = {working_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество обучения существенно взоросло. В данном случае лучший параметр C = 0.1. Это можно объяснить тем, что само значение идентификатора мало влияло на результат, значительно важнее был просто факт присутствия героя в игре."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по AUC-ROC для этой задачи лучше всего работает логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на обучающей выборке с C = 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 0.1)\n",
    "lr.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим и подготовим тестовую выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('features_test.csv', index_col = 'match_id')\n",
    "\n",
    "df.fillna(-1, inplace = True)\n",
    "\n",
    "data = df.as_matrix(columns = columns_to_scale)\n",
    "data = scaler.transform(data)\n",
    "for i, column in enumerate(columns_to_scale):\n",
    "    df[column] = data[:, i]\n",
    "        \n",
    "x_pick = np.zeros((df.shape[0], N))\n",
    "for i, match_id in enumerate(df.index):\n",
    "    for p in range(5):\n",
    "        x_pick[i, df.loc[match_id, 'r%d_hero' % (p+1)] - 1] = 1\n",
    "        x_pick[i, df.loc[match_id, 'd%d_hero' % (p+1)] - 1] = -1\n",
    "for i in range(N):\n",
    "    df[f\"Hero{i}\"] = x_pick[:, i]\n",
    "    \n",
    "for column in cat_columns:\n",
    "    df.drop(column, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим предсказания для тестовой выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16161213  0.83838787]\n",
      " [ 0.2262069   0.7737931 ]\n",
      " [ 0.79612991  0.20387009]\n",
      " ..., \n",
      " [ 0.77383724  0.22616276]\n",
      " [ 0.37848084  0.62151916]\n",
      " [ 0.5847073   0.4152927 ]]\n"
     ]
    }
   ],
   "source": [
    "proba = lr.predict_proba(df.as_matrix(columns = df.columns.difference(['start_time'])))\n",
    "print(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что вероятности адекватны:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dire: min = 0.003517865110973739, max = 0.9907292813617132, Unique values = 17177\n",
      "Radiant: min = 0.003517865110973739, max = 0.9907292813617132, Unique values = 17177\n"
     ]
    }
   ],
   "source": [
    "dire_proba = proba[:, 0]\n",
    "rad_proba = proba[:, 1]\n",
    "\n",
    "print(f\"Dire: min = {np.min(dire_proba)}, max = {np.max(dire_proba)}, Unique values = {np.unique(dire_proba).size}\")\n",
    "print(f\"Radiant: min = {np.min(dire_proba)}, max = {np.max(dire_proba)}, Unique values = {np.unique(dire_proba).size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим и сохраним файл для Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_test['match_id'] = df.index.values\n",
    "df_test['radiant_win'] = rad_proba\n",
    "\n",
    "df_test.to_csv('kaggle_results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
